# ml

1 - Implementation of Linear regression to find and plot the best fit line so that we can predict the response for any new feature
value of X using the Ordinary Least Squares (OLS) Method.

2 - Implementation of Linear regression to find and plot the best fit line so that we can predict the response for any new feature
value of X using the Gradient Descent Algorithm.

3 - Implementation of Multiple linear regression on Boston house pricing dataset using Scikit-learn.

4 - Mean, Median, Mode, Standard deviation, pearson correlation and covariance matrix using ‘wine.csv’ dataset.

5 - Calculation of the sum square error for polynomial curve fitting problem for polynomial degree=2.

6 - Generation of a synthetic dataset by taking X and Y values as:
    X: 6 random values in the range (1,3).
    Y: generate the values using y= 1.7+ 0.5*x
        a) Find out cost funcion value for 3 iterations.
        b) Draw the three different plots obtained for the three  regression lines (in 2 (a)) for different combinations of alpha0 and alpha1 (or “m” and “c”). 

7 - Code to implement the logistic regression for the Diabetes dataset. Apply 5-fold cross validation to find the best fold. 

8 - Code to implement logistic regression for the MNIST dataset. Note that it is a multi-class classification problem having 10 classes. 

9 - Implementation of a multilayer feedforward neural network considering the following specifications:
  1. Generate 1000 random data samples with 5 features and 2 classes that are not linearly separable. 
  2. Visualize the generated samples using a scatter plot. 
  3. Write from scratch a feedforward neural network.
  4. Implement the forward pass of the neural network on the generated data and calculate the mean square error loss. 

10 - Implementation of single layer perceptron (SLP) for the OR and AND problem without using inbuilt functions.
      Making sure of the followings:                                    
        a. Train the model for different learning rates (LR), where 0<LR<1. Train for 5 different learning rates and plot the training curve (epoch vs training                   accuracy).
        b. Weight initialization should be between -0.3 to 0.3
            F(x)= { 1, netx > 0 AND 0,  netx ≤ 0 }
            
11 - Implementation of a BPNN without using inbuilt functions. 
      Consider the following to design the network:                                                                     
        a. Two input nodes, two hidden nodes and two output nodes. 
        b. Values of the input nodes are 0.3 and 0.8 respectively.  Values of the output nodes are 0.05 and 0.6 respectively. 
        c. The weights values from input-hidden layers are 0.1, 0.3, 0.25, 0.8.
        d. The weights values from hidden-output layers are 0.2, 0.6, 0.4, 0.7.
        e. The activation to use is the Sigmoid activation function. 
        f. Bias is 1 for input and hidden layer. 
       
12 - Cluster the IRIS dataset using K-means algorithm without using any inbuilt library functions.

13 - Find the optimal value of K using the Elbow method on the IRIS dataset.

14 - K-means using in-built library functions on the IRIS dataset.

15 - Implementation of Naive Bayesian classifier to classify patterns from the Car Evaluation dataset.

16 - Implementation of Decision tree classifier to classify patterns from the Car Evaluation dataset.

18 - Classifying the IRIS dataset using kNN algorithm without using any inbuilt library functions.

19 - Finding the first two principal components of the IRIS dataset using Principal Component Analysis (PCA) algorithm without using any inbuilt library functions.
