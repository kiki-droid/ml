{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tFyya5CmnO96"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \t\n",
        "import matplotlib.pyplot as plt \n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_score(y_true, y_pred):\n",
        "\n",
        "\t\"\"\"\tscore = (y_true - y_pred) / len(y_true) \"\"\"\n",
        "\n",
        "\treturn round(float(sum(y_pred == y_true))/float(len(y_true)) * 100 ,2)\n",
        "\n",
        "def pre_processing(df):\n",
        "\n",
        "\t\"\"\" partioning data into features and target \"\"\"\n",
        "\n",
        "\tX = df.drop([df.columns[-1]], axis = 1)\n",
        "\ty = df[df.columns[-1]]\n",
        "\n",
        "\treturn X, y"
      ],
      "metadata": {
        "id": "2ZCLwHPYnV3i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class  NaiveBayes:\n",
        "\n",
        "\t\"\"\"\n",
        "\t\tBayes Theorem:\n",
        "\t\t\t\t\t\t\t\t\t\tLikelihood * Class prior probability\n",
        "\t\t\t\tPosterior Probability = -------------------------------------\n",
        "\t\t\t\t\t\t\t\t\t\t\tPredictor prior probability\n",
        "\t\t\t\t\n",
        "\t\t\t\t\t\t\t  \t\t\t P(x|c) * p(c)\n",
        "\t\t\t\t\t\t\t   P(c|x) = ------------------ \n",
        "\t\t\t\t\t\t\t\t\t\t\t  P(x)\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(self):\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\t\tAttributes:\n",
        "\t\t\t\tlikelihoods: Likelihood of each feature per class\n",
        "\t\t\t\tclass_priors: Prior probabilities of classes \n",
        "\t\t\t\tpred_priors: Prior probabilities of features \n",
        "\t\t\t\tfeatures: All features of dataset\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\tself.features = list\n",
        "\t\tself.likelihoods = {}\n",
        "\t\tself.class_priors = {}\n",
        "\t\tself.pred_priors = {}\n",
        "\n",
        "\t\tself.X_train = np.array\n",
        "\t\tself.y_train = np.array\n",
        "\t\tself.train_size = int\n",
        "\t\tself.num_feats = int\n",
        "\n",
        "\tdef fit(self, X, y):\n",
        "\n",
        "\t\tself.features = list(X.columns)\n",
        "\t\tself.X_train = X\n",
        "\t\tself.y_train = y\n",
        "\t\tself.train_size = X.shape[0]\n",
        "\t\tself.num_feats = X.shape[1]\n",
        "\n",
        "\t\tfor feature in self.features:\n",
        "\t\t\tself.likelihoods[feature] = {}\n",
        "\t\t\tself.pred_priors[feature] = {}\n",
        "\n",
        "\t\t\tfor feat_val in np.unique(self.X_train[feature]):\n",
        "\t\t\t\tself.pred_priors[feature].update({feat_val: 0})\n",
        "\n",
        "\t\t\t\tfor outcome in np.unique(self.y_train):\n",
        "\t\t\t\t\tself.likelihoods[feature].update({feat_val+'_'+outcome:0})\n",
        "\t\t\t\t\tself.class_priors.update({outcome: 0})\n",
        "\n",
        "\t\tself._calc_class_prior()\n",
        "\t\tself._calc_likelihoods()\n",
        "\t\tself._calc_predictor_prior()\n",
        "\n",
        "\tdef _calc_class_prior(self):\n",
        "\n",
        "\t\t\"\"\" P(c) - Prior Class Probability \"\"\"\n",
        "\n",
        "\t\tfor outcome in np.unique(self.y_train):\n",
        "\t\t\toutcome_count = sum(self.y_train == outcome)\n",
        "\t\t\tself.class_priors[outcome] = outcome_count / self.train_size\n",
        "\n",
        "\tdef _calc_likelihoods(self):\n",
        "\n",
        "\t\t\"\"\" P(x|c) - Likelihood \"\"\"\n",
        "\n",
        "\t\tfor feature in self.features:\n",
        "\n",
        "\t\t\tfor outcome in np.unique(self.y_train):\n",
        "\t\t\t\toutcome_count = sum(self.y_train == outcome)\n",
        "\t\t\t\ta = self.X_train[feature]\n",
        "\t\t\t\tc = self.y_train[self.y_train == outcome].index.values.tolist()\n",
        "\t\t\t\t# print(a, c, self.X_train, a.shape)\n",
        "\t\t\t\tb = []\n",
        "\t\t\t\tfor i in c:\n",
        "\t\t\t\t\ttry:\n",
        "\t\t\t\t\t\tb.append(a[i])\n",
        "\t\t\t\t\texcept:\n",
        "\t\t\t\t\t\tpass\n",
        "\t\t\t\tb = pd.DataFrame(b)\n",
        "\t\t\t\tfeat_likelihood = b.value_counts().to_dict()\n",
        "\n",
        "\t\t\t\tfor feat_val, count in feat_likelihood.items():\n",
        "\t\t\t\t\tself.likelihoods[feature][feat_val[0] + '_' + outcome] = count/outcome_count\n",
        "\n",
        "\n",
        "\tdef _calc_predictor_prior(self):\n",
        "\n",
        "\t\t\"\"\" P(x) - Evidence \"\"\"\n",
        "\n",
        "\t\tfor feature in self.features:\n",
        "\t\t\tfeat_vals = self.X_train[feature].value_counts().to_dict()\n",
        "\n",
        "\t\t\tfor feat_val, count in feat_vals.items():\n",
        "\t\t\t\tself.pred_priors[feature][feat_val] = count/self.train_size\n",
        "\n",
        "\n",
        "\tdef predict(self, X):\n",
        "\n",
        "\t\t\"\"\" Calculates Posterior probability P(c|x) \"\"\"\n",
        "\n",
        "\t\tresults = []\n",
        "\t\tX = np.array(X)\n",
        "\n",
        "\t\tfor query in X:\n",
        "\t\t\tprobs_outcome = {}\n",
        "\t\t\tfor outcome in np.unique(self.y_train):\n",
        "\t\t\t\tprior = self.class_priors[outcome]\n",
        "\t\t\t\tlikelihood = 1\n",
        "\t\t\t\tevidence = 1\n",
        "\n",
        "\t\t\t\tfor feat, feat_val in zip(self.features, query):\n",
        "\t\t\t\t\tlikelihood *= self.likelihoods[feat][feat_val + '_' + outcome]\n",
        "\t\t\t\t\tevidence *= self.pred_priors[feat][feat_val]\n",
        "\n",
        "\t\t\t\tposterior = (likelihood * prior) / (evidence)\n",
        "\n",
        "\t\t\t\tprobs_outcome[outcome] = posterior\n",
        "\n",
        "\t\t\tresult = max(probs_outcome, key = lambda x: probs_outcome[x])\n",
        "\t\t\tresults.append(result)\n",
        "\n",
        "\t\treturn np.array(results)"
      ],
      "metadata": {
        "id": "CnsXF7YPnfWx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\n",
        "    'car_evaluation.csv',\n",
        "    names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class'],\n",
        "    header = None,\n",
        "    index_col = False\n",
        ")\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDlUkk2cnj4J",
        "outputId": "9991aab2-2f94-463d-afe7-d8d68e695c33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  buying  maint doors persons lug_boot safety  class\n",
            "0  vhigh  vhigh     2       2    small    low  unacc\n",
            "1  vhigh  vhigh     2       2    small    med  unacc\n",
            "2  vhigh  vhigh     2       2    small   high  unacc\n",
            "3  vhigh  vhigh     2       2      med    low  unacc\n",
            "4  vhigh  vhigh     2       2      med    med  unacc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = pre_processing(df)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test = train_test_split(X, test_size = 0.10, random_state=0)\n",
        "y_train, y_test = train_test_split(y, test_size = 0.10, random_state=0)\n",
        "\n",
        "print('Train dataset size:', X_train.shape)\n",
        "print('Test dataset size:', X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kGFXvSgnuhq",
        "outputId": "5b79cf71-183e-40f5-cf10-629311aa5d33"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: (1555, 6)\n",
            "Test dataset size: (173, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_clf = NaiveBayes()\n",
        "nb_clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Train Accuracy: {}\".format(accuracy_score(y_train, nb_clf.predict(X_train))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsgveXbHn2FK",
        "outputId": "c807e34f-7aa5-4945-e78e-3e0697d285da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 86.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing Accuracy: {}\".format(accuracy_score(y_test, nb_clf.predict(X_test))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2czfxHUOn41p",
        "outputId": "d8cade46-c9fe-4799-bea8-d58aac84ba81"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 85.55\n"
          ]
        }
      ]
    }
  ]
}